import gradio as gr
import numpy as np
import uuid
import time
from fastapi import FastAPI

from fastrtc import Stream, ReplyOnPause, audio_to_bytes, AlgoOptions
from groq import Groq
from elevenlabs.client import ElevenLabs
from elevenlabs import VoiceSettings


from config import GROQ_API_KEY, STT_MODEL_NAME, ELEVENLABS_API_KEY, ELEVENLABS_VOICE_ID, TTS_MODEL_NAME
from agent.graph import agent_executor

# --- Kh·ªüi t·∫°o Clients ---
groq_client = Groq(api_key=GROQ_API_KEY)
tts_client = ElevenLabs(api_key=ELEVENLABS_API_KEY)

def response_generator(text_input: str, thread_id: str):
    """
    H√†m n√†y g·ªçi agent, l·∫•y k·∫øt qu·∫£ v√† log ra m√†n h√¨nh.
    """
    print(f"üí¨ [User - {thread_id}]: {text_input}")
    
    # C·∫•u h√¨nh ƒë·ªÉ LangGraph s·ª≠ d·ª•ng ƒë√∫ng lu·ªìng h·ªôi tho·∫°i
    config = {"configurable": {"thread_id": thread_id}}
    
    # G·ªçi agent ƒë·ªÉ x·ª≠ l√Ω
    agent_response = agent_executor.invoke(
        {"messages": [("user", text_input)]}, config=config
    )
    
    # L·∫•y c√¢u tr·∫£ l·ªùi cu·ªëi c√πng t·ª´ agent
    final_response = agent_response["messages"][-1].content
    print(f"ü§ñ [AI - {thread_id}]: {final_response}")
    
    return final_response


def voice_chat_handler(audio: tuple[int, np.ndarray], thread_id: str | None = None):
    """
    H√†m x·ª≠ l√Ω ch√≠nh c·ªßa FastRTC: nh·∫≠n audio, chuy·ªÉn th√†nh text,
    g·ªçi agent, nh·∫≠n text tr·∫£ v·ªÅ, chuy·ªÉn th√†nh audio v√† stream l·∫°i.
    """
    if audio is None:
        return
        
    start_time = time.time()
    
    # T·∫°o thread_id n·∫øu l√† l·∫ßn ƒë·∫ßu ti√™n
    if thread_id is None:
        thread_id = str(uuid.uuid4())
        
    # 1. Speech-to-Text v·ªõi Groq Whisper
    transcription = groq_client.audio.transcriptions.create(
        file=("audio.wav", audio_to_bytes(audio)),
        model=STT_MODEL_NAME,
        language="vi" # Ch·ªâ ƒë·ªãnh ng√¥n ng·ªØ l√† ti·∫øng Vi·ªát
    )
    user_text = transcription.text
    if not user_text.strip():
        print("üé§ √Çm thanh tr·ªëng, b·ªè qua.")
        return

    stt_time = time.time() - start_time
    print(f"‚è±Ô∏è STT time: {stt_time:.2f}s")
    
    # 2. L·∫•y c√¢u tr·∫£ l·ªùi t·ª´ Agent
    response_text = response_generator(user_text, thread_id)
    agent_time = time.time() - start_time - stt_time
    print(f"‚è±Ô∏è Agent response time: {agent_time:.2f}s")
    # print("C√°c ph∆∞∆°ng th·ª©c c√≥ s·∫µn cho text_to_speech:", dir(tts_client.text_to_speech))
    # 3. Text-to-Speech v·ªõi ElevenLabs (streaming)
    audio_stream = tts_client.text_to_speech.stream(
        text=response_text,
        voice_id=ELEVENLABS_VOICE_ID,
        model_id=TTS_MODEL_NAME,
        output_format="pcm_24000",
        # Th√™m c√†i ƒë·∫∑t gi·ªçng n√≥i ƒë·ªÉ bi·ªÉu c·∫£m
        voice_settings=VoiceSettings(
        stability=0.6,
        similarity_boost=0.8,
        style=0.3,
        use_speaker_boost=True
    )
        # stream=True
    )

    # 4. Stream audio tr·∫£ v·ªÅ cho ng∆∞·ªùi d√πng
    for chunk in audio_stream:
        if chunk:
            # ƒê·∫£m b·∫£o buffer lu√¥n c√≥ s·ªë byte ch·∫µn
            if len(chunk) % 2 != 0:
                chunk = chunk[:-1]

            # Ki·ªÉm tra l·∫°i xem chunk c√≥ c√≤n d·ªØ li·ªáu kh√¥ng sau khi c·∫Øt
            if not chunk:
                continue

            audio_array = np.frombuffer(chunk, dtype=np.int16).reshape(1, -1)
            yield (24000, audio_array)


# --- C·∫•u h√¨nh FastRTC Stream ---
stream = Stream(
    modality="audio",
    mode="send-receive",
    handler=ReplyOnPause(
        voice_chat_handler,
        algo_options=AlgoOptions(
            speech_threshold=0.5,  # Ng∆∞·ª°ng nh·∫≠n di·ªán gi·ªçng n√≥i
            # max_speech_duration=10,  # Th·ªùi gian t·ªëi ƒëa cho m·ªói ƒëo·∫°n n√≥i
        )
        # Th√™m m·ªôt input ·∫©n ƒë·ªÉ l∆∞u thread_id gi·ªØa c√°c l·∫ßn g·ªçi
    ),additional_inputs=[gr.State(None)],
    # C√†i ƒë·∫∑t ng∆∞·ª°ng nh·∫≠n di·ªán gi·ªçng n√≥i
    ui_args={"title": "AI Agent B·∫•t ƒê·ªông S·∫£n InGo üè°"}
)

# --- T·∫°o ·ª©ng d·ª•ng FastAPI v√† g·∫Øn giao di·ªán Gradio ---
app = FastAPI()
app = gr.mount_gradio_app(app, stream.ui, path="/")

if __name__ == "__main__":
    import uvicorn
    print("üî• Kh·ªüi ch·∫°y ·ª©ng d·ª•ng t·∫°i http://127.0.0.1:7860")
    uvicorn.run(app, host="127.0.0.1", port=7860)